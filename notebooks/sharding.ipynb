{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P14I5lii7lDL"
   },
   "source": [
    "# Data Sharding Across Devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raEPUBEj7lDM",
    "outputId": "4ffd7ece-20dc-4f1f-d7cb-0d82831044b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--xla_enable_async_all_gather=true TPU_MEGACORE=MEGACORE_DENSE --xla_tpu_use_enhanced_launch_barrier=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://symbolize.stripped_domain/r/?trace=7fd2f308f251,7fd3afa4251f,7fd2efc9f01e,7fd2efc9e4b7,7fd2efc9d6ec,7fd2efc9d39d,7fd2ec0a6ff1,7fd2ec099ce8,7fd2ec098529,7fd2ec0947aa,7fd2e9e2c759,7fd2e916990d,7fd2fc09aed3,7fd2fc09abab,7fd2fbf47d45,7fd30444a4e0,7fd3b01e4e37&map= \n",
      "*** SIGFPE (@0x7fd2f308f251), see go/stacktraces#s15 received by PID 103042 (TID 103042) on cpu 18; stack trace: ***\n",
      "PC: @     0x7fd2f308f251  (unknown)  (unknown)\n",
      "    @     0x7fd2f5d1f565       1904  (unknown)\n",
      "    @     0x7fd3afa42520  2052567888  (unknown)\n",
      "    @     0x7fd2efc9f01f        416  (unknown)\n",
      "    @     0x7fd2efc9e4b8        544  (unknown)\n",
      "    @     0x7fd2efc9d6ed         80  (unknown)\n",
      "    @     0x7fd2efc9d39e         96  (unknown)\n",
      "    @     0x7fd2ec0a6ff2       1248  (unknown)\n",
      "    @     0x7fd2ec099ce9        144  (unknown)\n",
      "    @     0x7fd2ec09852a        592  (unknown)\n",
      "    @     0x7fd2ec0947ab        272  (unknown)\n",
      "    @     0x7fd2e9e2c75a        320  (unknown)\n",
      "    @     0x7fd2e916990e        544  (unknown)\n",
      "    @     0x7fd2fc09aed4        304  xla::WrapClientAroundCApi()\n",
      "    @     0x7fd2fc09abac        112  xla::GetCApiClient()\n",
      "    @     0x7fd2fbf47d46        432  nanobind::detail::func_create<>()::{lambda()#1}::__invoke()\n",
      "    @     0x7fd30444a4e1        384  nanobind::detail::nb_func_vectorcall_complex()\n",
      "    @     0x7fd3b01e4e38  (unknown)  _PyEval_EvalFrameDefault\n",
      "https://symbolize.stripped_domain/r/?trace=7fd2f308f251,7fd2f5d1f564,7fd3afa4251f,7fd2efc9f01e,7fd2efc9e4b7,7fd2efc9d6ec,7fd2efc9d39d,7fd2ec0a6ff1,7fd2ec099ce8,7fd2ec098529,7fd2ec0947aa,7fd2e9e2c759,7fd2e916990d,7fd2fc09aed3,7fd2fc09abab,7fd2fbf47d45,7fd30444a4e0,7fd3b01e4e37&map= \n",
      "E0525 07:50:42.312228  103042 coredump_hook.cc:301] RAW: Remote crash data gathering hook invoked.\n",
      "E0525 07:50:42.312250  103042 coredump_hook.cc:340] RAW: Skipping coredump since rlimit was 0 at process start.\n",
      "E0525 07:50:42.312262  103042 client.cc:270] RAW: Coroner client retries enabled, will retry for up to 30 sec.\n",
      "E0525 07:50:42.312267  103042 coredump_hook.cc:396] RAW: Sending fingerprint to remote end.\n",
      "E0525 07:50:42.312296  103042 coredump_hook.cc:405] RAW: Cannot send fingerprint to Coroner: [NOT_FOUND] stat failed on crash reporting socket /var/google/services/logmanagerd/remote_coredump.socket (Is the listener running?): No such file or directory\n",
      "E0525 07:50:42.312302  103042 coredump_hook.cc:457] RAW: Dumping core locally.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import jax\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.environ[\"LIBTPU_INIT_ARGS\"])\n",
    "\n",
    "platform : Literal[\"darwin\", \"colab\", \"cuda\", \"tpu\"] = \"darwin\"\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    platform = \"colab\"\n",
    "except ImportError:\n",
    "    devices = jax.devices()\n",
    "    if any(d.platform == \"gpu\" for d in devices):\n",
    "        platform = \"cuda\"\n",
    "    elif any(d.platform == \"tpu\" for d in devices):\n",
    "        platform = \"tpu\"\n",
    "\n",
    "print(f\"Running on {platform}\")\n",
    "\n",
    "if platform == \"colab\":\n",
    "    !git clone https://github.com/novastar53/high_performance_jax\n",
    "    !cd high_performance_jax && git pull\n",
    "    !git clone https://github.com/novastar53/deepkit\n",
    "    !cd deepkit && git pull\n",
    "    hpj_dir = str(Path().absolute() / \"high_performance_jax\" / \"src\" )\n",
    "    dt_dir = str(Path().absolute() / \"deepkit\" / \"src\" )\n",
    "    sys.path.append(hpj_dir)\n",
    "    print(hpj_dir)\n",
    "    sys.path.append(dt_dir)\n",
    "    print(dt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGbIGN8L7lDM",
    "outputId": "20835f1d-a83d-4e6e-bcc1-63279a80178d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ[\"LIBTPU_INIT_ARGS\"])\n",
    "os.environ[\"LIBTPU_INIT_ARGS\"] = \"--xla_enable_async_all_gather=true TPU_MEGACORE=MEGACORE_DENSE\"\n",
    "print(os.environ[\"LIBTPU_INIT_ARGS\"])\n",
    "\n",
    "from deepkit.utils import timeit\n",
    "from high_performance_jax.single_chip_performance import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = jnp.bfloat16\n",
    "devices = jax.devices()\n",
    "print(\"Devices:\")\n",
    "for i,d in enumerate(devices):\n",
    "  print(f\"{i+1}. {d.device_kind}\")    # e.g. “TPU v3”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "iT0fCCet72yo",
    "outputId": "9225d972-0b3c-4598-a6a5-4517dd5d36be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">          TPU 0          </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m          \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m          \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = jnp.ones((1024, 1024))\n",
    "jax.debug.visualize_array_sharding(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srdVeJPBpajy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvOOHg1m8RBF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "device_array = np.array(jax.devices()).reshape((4,2))\n",
    "print(device_array)\n",
    "mesh = jax.sharding.Mesh(device_array, [\"myaxis1\", \"myaxis2\"])\n",
    "p = jax.sharding.PartitionSpec(\"myaxis2\", \"myaxis1\")\n",
    "sharding = jax.sharding.NamedSharding(mesh, p)\n",
    "sharded_A = jax.device_put(A, sharding)\n",
    "jax.debug.visualize_array_sharding(sharded_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv0D_WHq9uD6"
   },
   "outputs": [],
   "source": [
    "sharded_A.addressable_shards[0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vgq-E_dTpwGX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "dim = 8\n",
    "A = jnp.ones((dim, dim, dim))\n",
    "\n",
    "# Step 1: Create device mesh (no names needed)\n",
    "device_array = np.array(jax.devices()).reshape((2, 2, 2))\n",
    "# Step 3: Create positional sharding object\n",
    "sharding = jax.sharding.PositionalSharding(device_array)\n",
    "\n",
    "# Step 4: Place array on devices\n",
    "sharded_A = jax.device_put(A, sharding)\n",
    "\n",
    "# Step 5: Visualize sharding\"\n",
    "#jax.debug.visualize_array_sharding(sharded_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MWmMumop2qa"
   },
   "outputs": [],
   "source": [
    "sharded_A.addressable_shards[0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "GpuTxnrlbGxy",
    "outputId": "2e6222a0-d571-4778-ad6c-336a1d0a6f8e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m A = jnp.ones((\u001b[32m1024\u001b[39m, \u001b[32m1024\u001b[39m))\n\u001b[32m      2\u001b[39m B = jnp.ones((\u001b[32m1024\u001b[39m, \u001b[32m1024\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m device_array = \u001b[43mnp\u001b[49m.array(jax.devices()).reshape((\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      6\u001b[39m mesh = jax.sharding.Mesh(device_array, [\u001b[33m\"\u001b[39m\u001b[33mmyaxis1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmyaxis2\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      8\u001b[39m p_A = jax.sharding.PartitionSpec(\u001b[33m\"\u001b[39m\u001b[33mmyaxis1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmyaxis2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "A = jnp.ones((1024, 1024))\n",
    "B = jnp.ones((1024, 1024))\n",
    "\n",
    "device_array = np.array(jax.devices()).reshape((2, 4))\n",
    "\n",
    "mesh = jax.sharding.Mesh(device_array, [\"myaxis1\", \"myaxis2\"])\n",
    "\n",
    "p_A = jax.sharding.PartitionSpec(\"myaxis1\", \"myaxis2\")\n",
    "p_B = jax.sharding.PartitionSpec(\"myaxis2\", \"myaxis1\")\n",
    "\n",
    "sharding_A = jax.sharding.NamedSharding(mesh, p_A)\n",
    "sharding_B = jax.sharding.NamedSharding(mesh, p_B)\n",
    "\n",
    "sharded_A = jax.device_put(A, sharding_A)\n",
    "jax.debug.visualize_array_sharding(sharded_A)\n",
    "\n",
    "sharded_B = jax.device_put(B, sharding_B)\n",
    "jax.debug.visualize_array_sharding(sharded_B)\n",
    "\n",
    "C = sharded_A + sharded_B\n",
    "jax.debug.visualize_array_sharding(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fSSMs3D4fo-o",
    "outputId": "9996eca5-aff9-4817-ac02-9f2a902cb51e"
   },
   "outputs": [
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 8.00G. That was not possible. There are 7.48G free.; (0x0x0_HBM0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d5e1fe89fef4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_array_sharding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/array_creation.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, device)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanonicalize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_user_dtype_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ones\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_device_to_sharding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, sharding)\u001b[0m\n\u001b[1;32m   2902\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_sharding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2904\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzeros_like_shaped_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mbroadcast\u001b[0;34m(operand, sizes, out_sharding)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m   \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2249\u001b[0;31m   return broadcast_in_dim(operand, tuple(sizes) + np.shape(operand), dims,\n\u001b[0m\u001b[1;32m   2250\u001b[0m                           out_sharding=out_sharding)\n\u001b[1;32m   2251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mbroadcast_in_dim\u001b[0;34m(operand, shape, broadcast_dimensions, out_sharding)\u001b[0m\n\u001b[1;32m   2280\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     \u001b[0mdyn_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m   return broadcast_in_dim_p.bind(\n\u001b[0m\u001b[1;32m   2283\u001b[0m       \u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m       \u001b[0mbroadcast_dimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_canonicalization\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalize_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_true_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_true_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m_true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0mtrace_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mtrace_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdef_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, args, params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mcheck_eval_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_thread_local_state_disable_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_thread_local_state_disable_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_token_bufs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_token_bufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharded_runtime_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_executable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_sharded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 8.00G. That was not possible. There are 7.48G free.; (0x0x0_HBM0)"
     ]
    }
   ],
   "source": [
    "A = jnp.ones((2**16, 2**15))\n",
    "jax.debug.visualize_array_sharding(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAAgXbMGqBYk",
    "outputId": "fbe0c029-39d6-42a5-8914-dc6244cc1763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/t_alloc_array_8W4EMT3AF9\n",
      "RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 4.00G. That was not possible. There are 3.48G free.; (0x0x0_HBM0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No profile started",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;129m@jax\u001b[39m.jit\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34malloc_array\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp.array(\u001b[38;5;28minput\u001b[39m, dtype=jnp.bfloat16)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m avg_time = \u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43malloc_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43malloc_array\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#@partial(jax.jit, out_shardings = sharded_sharding)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#def shard_array(input):\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m#return input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m#avg_time = timeit(unshard_array, A_sharded, task='unshard_array')\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(avg_time)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/high_performance_jax/.venv/lib/python3.12/site-packages/deepkit/utils.py:61\u001b[39m, in \u001b[36mtimeit\u001b[39m\u001b[34m(f, tries, task, *args)\u001b[39m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m average_time_ms = \u001b[38;5;28msum\u001b[39m(outcomes_ms)/\u001b[38;5;28mlen\u001b[39m(outcomes_ms)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m average_time_ms\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/high_performance_jax/.venv/lib/python3.12/site-packages/jax/_src/profiler.py:202\u001b[39m, in \u001b[36mstop_trace\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _profile_state.lock:\n\u001b[32m    201\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _profile_state.profile_session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo profile started\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    203\u001b[39m   sess = _profile_state.profile_session\n\u001b[32m    204\u001b[39m   sess.export(sess.stop(), \u001b[38;5;28mstr\u001b[39m(_profile_state.log_dir))\n",
      "\u001b[31mRuntimeError\u001b[39m: No profile started"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import jax\n",
    "import numpy as np\n",
    "\n",
    "ROWS = 2**16\n",
    "COLS = 2**15\n",
    "\n",
    "A = np.ones((ROWS, COLS), dtype=np.float16)\n",
    "mesh = jax.sharding.Mesh(jax.devices(), (\"ouraxis\"))\n",
    "sharded_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"ouraxis\"))\n",
    "unsharded_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(None))\n",
    "\n",
    "@jax.jit\n",
    "def alloc_array(input):\n",
    "    return jnp.array(input, dtype=jnp.bfloat16)\n",
    "avg_time = timeit(alloc_array, A, task=\"alloc_array\")\n",
    "\n",
    "#@partial(jax.jit, out_shardings = sharded_sharding)\n",
    "#def shard_array(input):\n",
    "    #return input\n",
    "#avg_time = timeit(shard_array, A, task='shard_array')\n",
    "    \n",
    "#A_sharded = jax.device_put(A, sharded_sharding)\n",
    "\n",
    "\n",
    "#@partial(jax.jit, out_shardings = unsharded_sharding)\n",
    "#def unshard_array(input):\n",
    "#  return input\n",
    "\n",
    "#avg_time = timeit(unshard_array, A_sharded, task='unshard_array')\n",
    "print(avg_time)\n",
    "#A_unsharded = unshard_array(A)\n",
    "\n",
    "achieved_bandwidth_GB_s = A.size * 2 / 10**9 / (avg_time / 10**3)\n",
    "print(achieved_bandwidth_GB_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/t_unshard_array_IEJ5DA53SU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 07:42:56.180417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748158976.217553  100579 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748158976.228821  100579 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748158976.253570  100579 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748158976.253589  100579 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748158976.253594  100579 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748158976.253599  100579 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_time_ms=437.4933\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LIBTPU_INIT_ARGS\"] = \"--xla_enable_async_all_gather=true TPU_MEGACORE=MEGACORE_DENSE\"\n",
    "\n",
    "SIZE = 16384\n",
    "BATCH_PER_CHIP = 4096\n",
    "LAYERS = 4\n",
    "\n",
    "ACTIVATIONS = jnp.ones((BATCH_PER_CHIP*jax.device_count(), SIZE), dtype=jnp.bfloat16)\n",
    "Ws = [jnp.ones((SIZE, SIZE), dtype=jnp.bfloat16) for i in range(LAYERS)]\n",
    "\n",
    "mesh = jax.sharding.Mesh(jax.devices(), ('ouraxis'))\n",
    "activation_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec('ouraxis', None))\n",
    "weight_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec('ouraxis'))\n",
    "\n",
    "ACTIVATIONS = jax.device_put(ACTIVATIONS, activation_sharding)\n",
    "Ws = [ jax.device_put(W, weight_sharding) for W in Ws ]\n",
    "\n",
    "@jax.jit\n",
    "def matmul(_act, _weights):\n",
    "    for _weight in _weights: \n",
    "        _act =  _act @ _weight\n",
    "    return _act\n",
    "\n",
    "average_time_ms = timeit(matmul, ACTIVATIONS, Ws, task=\"unshard_array\")\n",
    "print(f\"{average_time_ms=}\")\n",
    "#achieved_bandwidth_GB_s = A.size * 2 / 10**9 / (average_time_ms / 10**3)\n",
    "#print(f\"{achieved_bandwidth_GB_s=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
