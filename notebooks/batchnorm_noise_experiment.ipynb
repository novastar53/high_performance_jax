{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "progress",
   "metadata": {},
   "source": [
    "## Progress Report & Next Steps\n",
    "\n",
    "**Last Updated:** January 29, 2025\n",
    "\n",
    "### Progress Made\n",
    "- ✅ Notebook structure created with 31 cells\n",
    "- ✅ All three model classes implemented:\n",
    "  - `VGGNet_BN` - Baseline with standard BatchNorm\n",
    "  - `VGGNet_NoisyBN` - Noisy version with forced ICS\n",
    "  - `VGGNet_NoBN` - Control without BatchNorm\n",
    "- ✅ Fixed PRNG key issue (Option 1 implementation):\n",
    "  - `NoisyVGGBlock` uses `master_noise_key` split during forward pass\n",
    "  - Noise only applied during training, disabled during evaluation\n",
    "- ✅ Training loop with all three models simultaneously\n",
    "- ✅ Real-time visualization (loss, train/test accuracy)\n",
    "- ✅ Results visualization and analysis code\n",
    "- ✅ Automated hypothesis testing\n",
    "- ✅ Validation and debugging checks\n",
    "\n",
    "### Current Configuration\n",
    "- Dataset: CIFAR-10 (no augmentation)\n",
    "- Batch size: 128\n",
    "- Architecture: VGG-style (10 conv + 3 FC layers)\n",
    "- Learning rate: 0.035\n",
    "- Momentum: 0.9\n",
    "- Noise parameters: nμ=0.5, nσ=1.25, rμ=0.1, rσ=0.1 (Santurkar et al)\n",
    "- Training epochs: 39\n",
    "- Random seeds: 1337 (models), 1338 (noise)\n",
    "\n",
    "### Status\n",
    "- Notebook is complete and ready to execute\n",
    "- All cells are syntactically valid\n",
    "- No known bugs blocking execution\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Phase 1: Initial Validation (DO THIS FIRST)**\n",
    "1. Run dataset loading cell - verify CIFAR-10 loads correctly\n",
    "2. Run model initialization cell - verify all three models initialize\n",
    "3. Run validation cell - check output shapes and noise behavior\n",
    "4. **STOP and verify all checks pass before proceeding**\n",
    "\n",
    "**Phase 2: Short Training Run**\n",
    "1. Modify `num_epochs = 3` (in training setup cell)\n",
    "2. Run training loop - verify:\n",
    "   - All models train without crashes\n",
    "   - Loss decreases for all models\n",
    "   - Accuracy improves\n",
    "   - Visualizations work correctly\n",
    "3. Check that noisy_bn produces different outputs on each call (stochastic)\n",
    "4. Stop and analyze short results\n",
    "\n",
    "**Phase 3: Full Experiment Execution**\n",
    "1. Restore `num_epochs = 39`\n",
    "2. Run full training loop (~6-8 hours expected)\n",
    "3. Monitor for issues:\n",
    "   - NaN losses or diverging\n",
    "   - Out-of-memory errors\n",
    "   - Training instability\n",
    "   - Unexpected long runtimes\n",
    "4. Wait for completion or interrupt early if needed\n",
    "\n",
    "**Phase 4: Results Analysis**\n",
    "1. Review final visualizations\n",
    "2. Check if hypothesis is supported (|Baseline BN - Noisy BN| < 2%)\n",
    "3. Document findings in analysis output\n",
    "4. Consider next experiments if needed\n",
    "\n",
    "### Expected Outcomes\n",
    "- **If Santurkar et al hypothesis is correct:**\n",
    "  - |Baseline BN - Noisy BN| < 2%\n",
    "  - Both BN models >> Non-BN\n",
    "  - This suggests BN effectiveness is independent of ICS reduction\n",
    "\n",
    "- **If hypothesis is NOT supported:**\n",
    "  - |Baseline BN - Noisy BN| > 2%\n",
    "  - May indicate issues with noise implementation\n",
    "  - May suggest ICS reduction plays a role\n",
    "\n",
    "### Known Issues to Watch For\n",
    "- Memory usage: 3 models simultaneously may be memory-intensive\n",
    "- Training time: ~6-8 hours, be prepared to wait or run overnight\n",
    "- Noise parameters: shift=1.0, scale=0.2 might need adjustment\n",
    "- PRNG key state: Ensure keys are properly managed during long training\n",
    "\n",
    "---\n",
    "**Ready to proceed with Phase 1 (Initial Validation)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Papers\n",
    "\n",
    "1. **Santurkar, S., Tsipras, D., Ilyas, A., & Madry, A. (2018).** [How does batch normalization help optimization?](https://arxiv.org/abs/1805.11604). NeurIPS 31.\n",
    "   - Key finding: BN's effectiveness is independent of Internal Covariate Shift (ICS) reduction\n",
    "   - Proposed mechanism: Loss landscape smoothing, gradient predictiveness, better initialization\n",
    "\n",
    "2. **Ioffe, S., & Szegedy, C. (2015).** [Batch normalization: Accelerating deep network training by reducing internal covariate shift](https://arxiv.org/abs/1502.03167). ICML 2015.\n",
    "   - Original ICS theory: BN reduces distributional shift in layer activations\n",
    "   - This notebook tests Santurkar's claim that ICS reduction is not the causal mechanism\n",
    "\n",
    "3. **Duchi, J., Hazan, E., Singer, Y., & Chandra, T. (2011).** [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](https://jmlr.org/papers/v12/duchi11a.html). JML 12(7):2121-2159.\n",
    "   - Original Adagrad optimizer with adaptive learning rates based on gradient history\n",
    "   - AdaGrad uses diagonal preconditioning - each dimension gets its own learning rate\n",
    "\n",
    "4. **Zeiler, M. D. (2012).** [ADADELTA: An Adaptive Learning Rate Method](https://arxiv.org/abs/1212.5701). Technical report.\n",
    "   - Introduced Adagrad with root mean squared propagation (RMSProp)\n",
    "   - Uses exponential moving average instead of cumulative sum, solving AdaGrad's vanishing gradient problem\n",
    "\n",
    "5. **Kingma, D. P., & Ba, J. (2015).** [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980). ICLR (2).\n",
    "   - Combines momentum (RMSProp) with adaptive learning rates\n",
    "   - Most widely used optimizer for deep learning\n",
    "\n",
    "6. **Loshchilov, I., & Hutter, F. (2017).** [Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101). ICLR (3).\n",
    "   - AdamW separates weight decay from adaptive learning rate for better regularization\n",
    "   - Addresses Adam's weight decay issues\n",
    "\n",
    "### Blog Posts & Tutorials\n",
    "\n",
    "1. [How Does Batch Normalization Work? Part 1](https://blog.vikrampawar.com/how-batchnorm-works.html) - Initial BN introduction and Ioffe's ICS theory\n",
    "2. [How Does Batch Normalization Work? Part 2](https://blog.vikrampawar.com/how-batchnorm-works-part-2.html) - Ioffe vs Santurkar comparison and landscape measurements\n",
    "\n",
    "### Optimization Theory\n",
    "\n",
    "1. [Preconditioning in Optimization](https://en.wikipedia.org/wiki/Preconditioning) - Mathematical foundation for rescaling the optimization problem\n",
    "2. [Lipschitz Continuity](https://en.wikipedia.org/wiki/Lipschitz_continuity) - Smoothness properties of functions\n",
    "3. [Gradient Descent Algorithms](https://en.wikipedia.org/wiki/Gradient_descent#Momentum) - Background on momentum methods\n",
    "\n",
    "### Related Work\n",
    "\n",
    "1. [How Does Batch Normalization Help Optimization? - Paper Analysis](https://arxiv.org/abs/1805.11604) - Santurkar et al paper with experiments\n",
    "2. [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167) - Original Ioffe & Szegedy paper3. [Understanding the Failure of Batch Normalization for Transformers in NLP](https://arxiv.org/abs/2002.03388) - BN issues with sequence models\n",
    "### Implementation Resources\n",
    "\n",
    "1. [Flax Documentation](https://flax.readthedocs.io/en/latest/index.html) - Framework used for model implementation\n",
    "2. [JAX Documentation](https://jax.readthedocs.io/en/latest/index.html) - Autograd and JIT compilation library\n",
    "3. [Optax](https://optax.readthedocs.io/en/latest/index.html) - Optimization library with standard optimizers\n",
    "\n",
    "### Tools & Libraries\n",
    "\n",
    "1. [deepkit](https://github.com/novastar53/deepkit) - Custom utilities for experiments (datasets, loggers, metrics)\n",
    "2. [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html) - Image classification dataset used in experiments3. [Matplotlib](https://matplotlib.org/) - Visualization library\n",
    "4. [Seaborn](https://seaborn.pydata.org/) - Statistical data visualization (plotting style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# BatchNorm Noise Injection Experiment\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook replicates Santurkar et al (2018) experiment demonstrating that BatchNorm's effectiveness is independent of Internal Covariate Shift (ICS) reduction.\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "BatchNorm's benefits come from **structural smoothing of loss landscape**, not from reducing distributional ICS. If this is true:\n",
    "\n",
    "- **Baseline BN** ≈ **Noisy BN** (similar performance)\n",
    "- Both BN models >> **Non-BN** (significantly better)\n",
    "\n",
    "### Experiment Design\n",
    "\n",
    "1. **Baseline BN:** Standard VGG + BatchNorm\n",
    "2. **Noisy BN:** VGG + BatchNorm with forced random shift/scale noise after BN normalization (per Algorithm 1)\n",
    "3. **Non-BN:** VGG without BatchNorm\n",
    "\n",
    "All models use identical:\n",
    "- Architecture (10 conv layers + 3 FC layers)\n",
    "- Initialization (same random seed)\n",
    "- Hyperparameters (lr=0.035, momentum=0.9)\n",
    "- Training conditions (39 epochs, CIFAR-10)\n",
    "\n",
    "### Expected Results (Santurkar et al)\n",
    "\n",
    "If ICS reduction is NOT causal mechanism:\n",
    "- Noisy BN should achieve similar performance to Baseline BN despite forced high ICS\n",
    "- Both BN models should significantly outperform Non-BN\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Santurkar, S., Tsipras, D., Ilyas, A., & Madry, A. (2018). [How does batch normalization help optimization?](https://arxiv.org/abs/1805.11604). NeurIPS 31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "\n",
    "Import all necessary libraries and configure plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.nnx as nnx\n",
    "import optax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "from deepkit.datasets import load_CIFAR10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-header",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "Load CIFAR-10 dataset without augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dataset-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 391\n",
      "Test batches: 79\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_CIFAR10(augment=False)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "Define three model variants:\n",
    "1. **Baseline BN:** Standard VGG block with BatchNorm\n",
    "2. **Noisy BN:** VGG block with BatchNorm + forced noise before BN\n",
    "3. **Non-BN:** VGG block without BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-bn",
   "metadata": {},
   "source": [
    "### Baseline VGG Block (Standard BN)\n",
    "\n",
    "Standard VGG block with BatchNorm after convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baseline-bn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = nnx.initializers.glorot_normal()\n",
    "class VGGBlock(nnx.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, rngs: nnx.Rngs):\n",
    "        self.conv = nnx.Conv(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            kernel_size=(3, 3),\n",
    "            kernel_init=kernel_init,\n",
    "            padding='SAME',\n",
    "            rngs=rngs\n",
    "        )\n",
    "        self.bn = nnx.BatchNorm(num_features=out_features, momentum=0.90, rngs=rngs)\n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = nnx.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noisy-bn",
   "metadata": {},
   "source": [
    "### Noisy VGG Block (BN + Forced Noise)\n",
    "\n",
    "Apply noise AFTER BatchNorm following Santurkar et al Algorithm 1.\n",
    "\n",
    "**Key Features:**\n",
    "- Two-level hierarchical sampling (per-unit parameters, then per-sample noise)\n",
    "- Noise only applied during training (not evaluation)\n",
    "- For convolutional layers, treats (batch, height, width) as batch dimension\n",
    "- Parameters: nμ=0.5, nσ=1.25, rμ=0.1, rσ=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "noisy-bn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyVGGBlock(nnx.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        *, \n",
    "        rngs: nnx.Rngs\n",
    "    ):\n",
    "        self.conv = nnx.Conv(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            kernel_size=(3, 3), \n",
    "            kernel_init=kernel_init, \n",
    "            padding='SAME', \n",
    "            rngs=rngs\n",
    "        )\n",
    "        self.n_mu = 0.5\n",
    "        self.n_sigma = 1.25\n",
    "        self.r_mu = 0.1\n",
    "        self.r_sigma = 0.1\n",
    "        self.master_noise_key = nnx.Variable(jax.random.PRNGKey(0))\n",
    "        self.bn = nnx.BatchNorm(num_features=out_features, momentum=0.90, rngs=rngs)\n",
    "        self.training = True\n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.training:\n",
    "            key, subkey = jax.random.split(self.master_noise_key.value)\n",
    "            self.master_noise_key.value = key\n",
    "            \n",
    "            x_shape = x.shape\n",
    "            batch_size, h, w, num_features = x_shape\n",
    "            \n",
    "            key, subkey = jax.random.split(subkey)\n",
    "            mu_t = jax.random.uniform(subkey, (num_features,), minval=-self.n_mu, maxval=self.n_mu)\n",
    "            \n",
    "            key, subkey = jax.random.split(subkey)\n",
    "            sigma_t = jax.random.uniform(subkey, (num_features,), minval=1.0, maxval=self.n_sigma)\n",
    "            \n",
    "            key, subkey = jax.random.split(subkey)\n",
    "            m_t = jax.random.uniform(subkey, x_shape, minval=mu_t[None, None, None, :] - self.r_mu, maxval=mu_t[None, None, None, :] + self.r_mu)\n",
    "            \n",
    "            key, subkey = jax.random.split(subkey)\n",
    "            s_t = jax.random.normal(subkey, x_shape) * self.r_sigma + sigma_t[None, None, None, :]\n",
    "            \n",
    "            x = s_t * x + m_t\n",
    "        x = nnx.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "non-bn",
   "metadata": {},
   "source": [
    "### Non-BN VGG Block\n",
    "\n",
    "VGG block without BatchNorm (control for comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "non-bn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoBNVGGBlock(nnx.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, rngs: nnx.Rngs):\n",
    "        self.conv = nnx.Conv(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            kernel_size=(3, 3), \n",
    "            kernel_init=kernel_init, \n",
    "            padding='SAME', \n",
    "            rngs=rngs\n",
    "        )\n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = nnx.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "full-networks",
   "metadata": {},
   "source": [
    "### Full VGG Network Architectures\n",
    "\n",
    "Three complete network architectures with identical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "full-networks-code",
   "metadata": {},
   "outputs": [],
   "source": [
         "# Baseline BN Network\n",
    "class VGGNet_BN(nnx.Module):\n",
    "    def __init__(self, rngs: nnx.Rngs):\n",
    "        self.convs = nnx.List([\n",
    "            VGGBlock(in_features=3, out_features=64, rngs=rngs), \n",
    "            VGGBlock(in_features=64, out_features=64, rngs=rngs), \n",
    "            VGGBlock(in_features=64, out_features=128, rngs=rngs), \n",
    "            VGGBlock(in_features=128, out_features=128, rngs=rngs), \n",
    "            VGGBlock(in_features=128, out_features=256, rngs=rngs), \n",
    "            VGGBlock(in_features=256, out_features=256, rngs=rngs), \n",
    "            VGGBlock(in_features=256, out_features=512, rngs=rngs), \n",
    "            VGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            VGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            VGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            VGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "        ])\n",
    "        self.fc1 = nnx.Linear(in_features=512, out_features=96, kernel_init=kernel_init, rngs=rngs) \n",
    "        self.fc2 = nnx.Linear(in_features=96, out_features=96, kernel_init=kernel_init, rngs=rngs) \n",
    "        self.out = nnx.Linear(in_features=96, out_features=10, kernel_init=kernel_init, rngs=rngs) \n",
    "    def __call__(self, x):\n",
    "        max_pool_after = [1, 3, 5, 7, 9]\n",
    "        for conv_idx in range(len(self.convs)):\n",
    "            x = self.convs[conv_idx](x) \n",
    "            if conv_idx in max_pool_after: \n",
    "                x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2)) \n",
    "        x = x.squeeze() \n",
    "        x = self.fc1(x) \n",
    "        x = nnx.relu(x) \n",
    "        x = self.fc2(x) \n",
    "        x = nnx.relu(x) \n",
    "        x = self.out(x) \n",
    "        return x\n",
    "\n",
         "# Noisy BN Network\n",
    "class VGGNet_NoisyBN(nnx.Module):\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.convs = nnx.List([\n",
    "            NoisyVGGBlock(in_features=3, out_features=64, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=64, out_features=64, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=64, out_features=128, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=128, out_features=128, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=128, out_features=256, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=256, out_features=256, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=256, out_features=512, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            NoisyVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "        ]) \n",
    "        block_rng = jax.random.PRNGKey(1338) \n",
    "        for block in self.convs: \n",
    "            block_rng, subkey = jax.random.split(block_rng) \n",
    "            block.master_noise_key.value = subkey \n",
    "        self.fc1 = nnx.Linear(in_features=512, out_features=96, kernel_init=kernel_init, rngs=rngs) \n",
    "        self.fc2 = nnx.Linear(in_features=96, out_features=96, kernel_init=kernel_init, rngs=rngs) \n",
    "        self.out = nnx.Linear(in_features=96, out_features=10, kernel_init=kernel_init, rngs=rngs) \n",
    "    def __call__(self, x):\n",
    "        max_pool_after = [1, 3, 5, 7, 9]\n",
    "        for conv_idx in range(len(self.convs)): \n",
    "            x = self.convs[conv_idx](x) \n",
    "            if conv_idx in max_pool_after: \n",
    "                x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2)) \n",
    "        x = x.squeeze() \n",
    "        x = self.fc1(x) \n",
    "        x = nnx.relu(x) \n",
    "        x = self.fc2(x) \n",
    "        x = nnx.relu(x) \n",
    "        x = self.out(x) \n",
    "        return x\n",
    "\n",
         "# Non-BN Network\n",
    "class VGGNet_NoBN(nnx.Module):\n",
    "    def __init__(self, rngs: nnx.Rngs):\n",
    "        self.convs = nnx.List([\n",
    "            NoBNVGGBlock(in_features=3, out_features=64, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=64, out_features=64, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=64, out_features=128, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=128, out_features=128, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=128, out_features=256, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=256, out_features=256, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=256, out_features=512, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "            NoBNVGGBlock(in_features=512, out_features=512, rngs=rngs), \n",
    "        ])\n",
    "        self.fc1 = nnx.Linear(in_features=512, out_features=96, kernel_init=kernel_init, rngs=rngs) \n",
    "        self.fc2 = nnx.Linear(in_features=96, out_features=96, kernel_init=kernel_init, rngs=rngs) \n",
    "        self.out = nnx.Linear(in_features=96, out_features=10, kernel_init=kernel_init, rngs=rngs) \n",
    "    def __call__(self, x):\n",
    "        max_pool_after = [1, 3, 5, 7, 9]\n",
    "        for conv_idx in range(len(self.convs)): \n",
    "            x = self.convs[conv_idx](x) \n",
    "            if conv_idx in max_pool_after: \n",
    "                x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2)) \n",
    "        x = x.squeeze() \n",
    "        x = self.fc1(x) \n",
    "        x = nnx.relu(x) \n",
    "        x = self.fc2(x) \n",
    "        x = nnx.relu(x) \n",
    "        x = self.out(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initialization",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Initialize all three models with identical seed. Verify parameter counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initialization-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BN: 11,831,242 parameters\n",
      "Noisy BN: 11,831,242 parameters\n",
      "Non-BN: 11,824,330 parameters\n"
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.key(1337) \n",
    "rngs = nnx.Rngs(rng_key) \n",
    "baseline_bn = VGGNet_BN(rngs=nnx.Rngs(rng_key)) \n",
    "noisy_bn = VGGNet_NoisyBN(rngs=nnx.Rngs(rng_key)) \n",
    "non_bn = VGGNet_NoBN(rngs=nnx.Rngs(rng_key)) \n",
    "\n",
    "#def count_params(model):\n",
    "#    return sum(x.size for x in jax.tree_util.tree_leaves(model) \n",
    "#                #if isinstance(x, (jnp.ndarray, jax.Array)) and not x.dtype.name.startswith('key')) \n",
    "#                if isinstance(x, (jnp.ndarray, jax.Array)) and not x.dtype.name.startswith('key')) \n",
    "#\n",
    "\n",
    "def count_params(m: nnx.Module, layer_type: str | None = None) -> int:\n",
    "    def get_size(y):\n",
    "        return y.size\n",
    "    \n",
    "    def exclude_noise_keys(path, val):\n",
    "        is_param = issubclass(val.type, nnx.Param)\n",
    "        path_str = '/'.join(map(str, path))\n",
    "        return is_param and 'noise_key' not in path_str\n",
    "    \n",
    "    if layer_type is not None:\n",
    "        def _filter(path, val):\n",
    "            return issubclass(val.type, nnx.Param) and layer_type in path\n",
    "        _, params, _ = nnx.split(m, _filter, nnx.Variable)\n",
    "    else:\n",
    "        _, params, _ = nnx.split(m, exclude_noise_keys, nnx.Variable)\n",
    "    param_counts = jax.tree_util.tree_map(get_size, params)\n",
    "    total_params = jax.tree_util.tree_reduce(\n",
    "        lambda x, y: x + y, param_counts, 0\n",
    "    )\n",
    "\n",
    "    return total_params\n",
    "\n",
    "\n",
    "baseline_params = count_params(baseline_bn) \n",
    "noisy_params = count_params(noisy_bn) \n",
    "non_params = count_params(non_bn) \n",
    "\n",
    "print(f\"Baseline BN: {baseline_params:,} parameters\") \n",
    "print(f\"Noisy BN: {noisy_params:,} parameters\") \n",
    "print(f\"Non-BN: {non_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-setup",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Configure optimizers, loss function, and training utilities (same as Part 2 for consistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "training-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.035\n",
    "momentum = 0.9\n",
    "\n",
    "baseline_opt = nnx.Optimizer(baseline_bn, optax.sgd(learning_rate=lr, momentum=momentum, nesterov=False))\n",
    "noisy_opt = nnx.Optimizer(noisy_bn, optax.sgd(learning_rate=lr, momentum=momentum, nesterov=False))\n",
    "non_opt = nnx.Optimizer(non_bn, optax.sgd(learning_rate=lr, momentum=momentum, nesterov=False))\n",
    "\n",
    "def loss_fn(model, batch, targets):\n",
    "    logits = model(batch)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets).mean()\n",
    "    return loss\n",
    "\n",
    "@nnx.jit\n",
    "def accuracy(model, batch, labels):\n",
    "    logits = model(batch)\n",
    "    preds = jnp.argmax(logits, axis=-1)\n",
    "    acc = jnp.sum(preds == labels) / logits.shape[0]\n",
    "    return acc\n",
    "\n",
    "@nnx.jit\n",
    "def step_fn(model: nnx.Module, optimizer: nnx.Optimizer, batch: jax.Array, labels: jax.Array):\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model, batch, labels)\n",
    "    optimizer.update(grads)\n",
    "    return loss\n",
    "\n",
    "def test_accuracy(model: nnx.Module, testloader):\n",
    "    acc, n = 0, 0\n",
    "    for batch, labels in testloader:\n",
    "        batch = jnp.array(batch)\n",
    "        labels = jnp.array(labels)\n",
    "        acc += accuracy(model, batch, labels)\n",
    "        n += 1\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-loop",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train all three models simultaneously and track performance metrics.\n",
    "\n",
    "**Expected Duration:** ~6-8 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "training-loop-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "  Baseline BN - loss: 2.4405, test_acc: 0.101\n",
      "  Noisy BN    - loss: 2.5223, test_acc: 0.099\n",
      "  Non-BN      - loss: 2.3027, test_acc: 0.105\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received KeyboardInterrupt. Exiting...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 39\n",
    "print_interval = 20\n",
    "test_interval = 200\n",
    "\n",
    "i = 0\n",
    "baseline_train_losses, noisy_train_losses, non_train_losses = [], [], []\n",
    "baseline_train_accs, noisy_train_accs, non_train_accs = [], [], []\n",
    "baseline_test_accs, noisy_test_accs, non_test_accs = [], [], []\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, labels in train_loader:\n",
    "            batch = jnp.array(batch)\n",
    "            labels = jnp.array(labels)\n",
    "\n",
    "            baseline_bn.train()\n",
    "            noisy_bn.train()\n",
    "            non_bn.train()\n",
    "\n",
    "            baseline_loss = step_fn(baseline_bn, baseline_opt, batch, labels)\n",
    "            noisy_loss = step_fn(noisy_bn, noisy_opt, batch, labels)\n",
    "            non_loss = step_fn(non_bn, non_opt, batch, labels)\n",
    "\n",
    "            baseline_train_losses.append(baseline_loss)\n",
    "            noisy_train_losses.append(noisy_loss)\n",
    "            non_train_losses.append(non_loss)\n",
    "\n",
    "            baseline_acc = accuracy(baseline_bn, batch, labels)\n",
    "            noisy_acc = accuracy(noisy_bn, batch, labels)\n",
    "            non_acc = accuracy(non_bn, batch, labels)\n",
    "\n",
    "            baseline_train_accs.append(baseline_acc)\n",
    "            noisy_train_accs.append(noisy_acc)\n",
    "            non_train_accs.append(non_acc)\n",
    "\n",
    "            baseline_bn.eval()\n",
    "            noisy_bn.eval()\n",
    "            non_bn.eval()\n",
    "\n",
    "            if i % test_interval == 0:\n",
    "                baseline_test_acc = test_accuracy(baseline_bn, test_loader)\n",
    "                noisy_test_acc = test_accuracy(noisy_bn, test_loader)\n",
    "                non_test_acc = test_accuracy(non_bn, test_loader)\n",
    "\n",
    "                baseline_test_accs.append(baseline_test_acc)\n",
    "                noisy_test_accs.append(noisy_test_acc)\n",
    "                non_test_accs.append(non_test_acc)\n",
    "\n",
    "            if i % print_interval == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"iter: {i}\")\n",
    "                print(f\"  Baseline BN - loss: {baseline_loss:0.4f}, test_acc: {baseline_test_acc:0.3f}\")\n",
    "                print(f\"  Noisy BN    - loss: {noisy_loss:0.4f}, test_acc: {noisy_test_acc:0.3f}\")\n",
    "                print(f\"  Non-BN      - loss: {non_loss:0.4f}, test_acc: {non_test_acc:0.3f}\")\n",
    "\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "                axes[0].plot(baseline_train_losses, alpha=0.9, label='Baseline BN')\n",
    "                axes[0].plot(noisy_train_losses, alpha=0.7, label='Noisy BN')\n",
    "                axes[0].plot(non_train_losses, alpha=0.5, label='Non-BN')\n",
    "                axes[0].set_title('Training Loss')\n",
    "                axes[0].legend()\n",
    "                axes[1].plot(baseline_train_accs, alpha=0.9, label='Baseline BN')\n",
    "                axes[1].plot(noisy_train_accs, alpha=0.7, label='Noisy BN')\n",
    "                axes[1].plot(non_train_accs, alpha=0.5, label='Non-BN')\n",
    "                axes[1].set_title('Train Accuracy')\n",
    "                axes[1].legend()\n",
    "                x = list(range(len(baseline_test_accs)))\n",
    "                x = [i * 200 for i in x]\n",
    "                axes[2].plot(x, baseline_test_accs, alpha=0.9, label='Baseline BN')\n",
    "                axes[2].plot(x, noisy_test_accs, alpha=0.7, label='Noisy BN')\n",
    "                axes[2].plot(x, non_test_accs, alpha=0.5, label='Non-BN')\n",
    "                axes[2].set_title('Test Accuracy')\n",
    "                axes[2].legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            i += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Received KeyboardInterrupt. Exiting...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "After training completes, create comprehensive comparison visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes[0, 0].plot(baseline_train_losses, alpha=0.9, label='Baseline BN')\n",
    "axes[0, 0].plot(noisy_train_losses, alpha=0.7, label='Noisy BN')\n",
    "axes[0, 0].plot(non_train_losses, alpha=0.5, label='Non-BN')\n",
    "axes[0, 0].set_title('Training Loss Comparison')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_yscale('log')\n",
    "axes[0, 1].plot(baseline_train_accs, alpha=0.9, label='Baseline BN')\n",
    "axes[0, 1].plot(noisy_train_accs, alpha=0.7, label='Noisy BN')\n",
    "axes[0, 1].plot(non_train_accs, alpha=0.5, label='Non-BN')\n",
    "axes[0, 1].set_title('Train Accuracy Comparison')\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "x = list(range(len(baseline_test_accs)))\n",
    "x = [i * 200 for i in x]\n",
    "axes[1, 0].plot(x, baseline_test_accs, 'o-', alpha=0.9, label='Baseline BN')\n",
    "axes[1, 0].plot(x, noisy_test_accs, 's-', alpha=0.7, label='Noisy BN')\n",
    "axes[1, 0].plot(x, non_test_accs, '^-', alpha=0.5, label='Non-BN')\n",
    "axes[1, 0].set_title('Test Accuracy Comparison')\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "final_accuracies = [baseline_test_accs[-1], noisy_test_accs[-1], non_test_accs[-1]]\n",
    "axes[1, 1].bar(['Baseline BN', 'Noisy BN', 'Non-BN'], final_accuracies, \n",
    "                 color=['blue', 'orange', 'red'], alpha=0.7)\n",
    "axes[1, 1].set_title('Final Test Accuracy')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "for i, v in enumerate(final_accuracies):\n",
    "    axes[1, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis",
   "metadata": {},
   "source": [
    "## Analysis & Discussion\n",
    "\n",
    "Automated analysis of results with hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nFinal Performance:\")\n",
    "print(f\"  Baseline BN - Test Accuracy: {baseline_test_accs[-1]:.4f}\")\n",
    "print(f\"  Noisy BN    - Test Accuracy: {noisy_test_accs[-1]:.4f}\")\n",
    "print(f\"  Non-BN      - Test Accuracy: {non_test_accs[-1]:.4f}\")\n",
    "print(\"\\nConvergence Speed (iterations to 80% test accuracy):\")\n",
    "def find_convergence(accs, target=0.8):\n",
    "    x = list(range(len(accs)))\n",
    "    x = [i * 200 for i in x]\n",
    "    for i, acc in enumerate(accs):\n",
    "        if acc >= target:\n",
    "            return x[i]\n",
    "    return None\n",
    "baseline_conv = find_convergence(baseline_test_accs)\n",
    "noisy_conv = find_convergence(noisy_test_accs)\n",
    "non_conv = find_convergence(non_test_accs)\n",
    "print(f\"  Baseline BN: {baseline_conv if baseline_conv else 'Not reached'}\")\n",
    "print(f\"  Noisy BN:    {noisy_conv if noisy_conv else 'Not reached'}\")\n",
    "print(f\"  Non-BN:      {non_conv if non_conv else 'Not reached'}\")\n",
    "print(\"\\nKey Observation:\")\n",
    "diff_baseline_noisy = abs(baseline_test_accs[-1] - noisy_test_accs[-1])\n",
    "diff_baseline_non = abs(baseline_test_accs[-1] - non_test_accs[-1])\n",
    "print(f\"  |Baseline BN - Noisy BN|: {diff_baseline_noisy:.4f}\")\n",
    "print(f\"  |Baseline BN - Non-BN|:    {diff_baseline_non:.4f}\")\n",
    "if diff_baseline_noisy < 0.02:\n",
    "    print(\"\\n✓ Result supports Santurkar et al hypothesis:\")\n",
    "    print(\"  Noisy BN performance ≈ Baseline BN performance\")\n",
    "    print(\"  This suggests BN effectiveness is independent of ICS reduction\")\n",
    "else:\n",
    "    print(\"\\n✗ Result does NOT support Santurkar et al hypothesis:\")\n",
    "    print(\"  Noisy BN performance differs significantly from Baseline BN\")\n",
    "    print(\"  This may indicate issues with noise implementation or parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation",
   "metadata": {},
   "source": [
    "## Validation & Debugging\n",
    "\n",
    "Optional validation checks before running full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_batch = jnp.ones((4, 32, 32, 3))\n",
    "baseline_out = baseline_bn(dummy_batch)\n",
    "noisy_out = noisy_bn(dummy_batch)\n",
    "non_out = non_bn(dummy_batch)\n",
    "assert baseline_out.shape == (4, 10), f\"Baseline BN output shape: {baseline_out.shape}\"\n",
    "assert noisy_out.shape == (4, 10), f\"Noisy BN output shape: {noisy_out.shape}\"\n",
    "assert non_out.shape == (4, 10), f\"Non-BN output shape: {non_out.shape}\"\n",
    "print(\"✓ Output shapes match\")\n",
    "noisy_bn.train()\n",
    "noisy_out1 = noisy_bn(dummy_batch)\n",
    "noisy_out2 = noisy_bn(dummy_batch)\n",
    "assert not jnp.array_equal(noisy_out1, noisy_out2), \"Noise not stochastic\"\n",
    "print(\"✓ Noise is stochastic (different each call)\")\n",
    "noisy_bn.eval()\n",
    "noisy_out3 = noisy_bn(dummy_batch)\n",
    "noisy_out4 = noisy_bn(dummy_batch)\n",
    "assert jnp.array_equal(noisy_out3, noisy_out4), \"Noise applied during eval\"\n",
    "print(\"✓ Noise disabled during evaluation\")\n",
    "test_batch = jnp.ones((4, 32, 32, 3))\n",
    "test_labels = jnp.array([0, 1, 2, 3])\n",
    "test_loss = step_fn(baseline_bn, baseline_opt, test_batch, test_labels)\n",
    "assert isinstance(test_loss, (float, jnp.ndarray)), f\"Loss type: {type(test_loss)}\"\n",
    "print(\"✓ Training step function works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Summary\n",
    "\n",
    "This experiment tests Santurkar et al (2018) hypothesis that BatchNorm's effectiveness is independent of Internal Covariate Shift (ICS) reduction.\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "If results show **Baseline BN ≈ Noisy BN >> Non-BN**:\n",
    "- Supports Santurkar et al's theory\n",
    "- Suggests BN's benefits come from structural smoothing, not ICS reduction\n",
    "- Demonstrates BN's adaptability (γ,β compensate for forced noise)\n",
    "\n",
    "If results show **Baseline BN >> Noisy BN**:\n",
    "- Contradicts Santurkar et al's theory\n",
    "- May indicate issues with noise implementation\n",
    "- Suggests ICS reduction may play a role\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Landscape Measurements:** Add loss Lipschitzness and gradient predictiveness (as in Part 2)\n",
    "2. **ICS Quantification:** Measure both distributional and gradient-based ICS to verify noise actually increases ICS\n",
    "3. **Noise Ablation:** Test different noise levels and distributions\n",
    "4. **Additional Controls:** Compare against other regularizers (dropout, weight decay)\n",
    "\n",
    "### References\n",
    "\n",
    "- Santurkar, S., Tsipras, D., Ilyas, A., & Madry, A. (2018). [How does batch normalization help optimization?](https://arxiv.org/abs/1805.11604). NeurIPS 31.\n",
    "- Ioffe, S., & Szegedy, C. (2015). [Batch normalization: Accelerating deep network training by reducing internal covariate shift](https://arxiv.org/abs/1502.03167). ICML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "high-performance-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
